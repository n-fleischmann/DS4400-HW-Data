{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Noah_Fleischmann_ML_HW3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOIAQEwCfTlDbWTDBSjd0l2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/n-fleischmann/DS4400-HW-Data/blob/main/Noah_Fleischmann_ML_HW3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HW 3\n",
        "\n",
        "Importing Data"
      ],
      "metadata": {
        "id": "y9qZHcVtAnVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import sklearn.metrics as m\n",
        "from math import e\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "4S215v5NAmgb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Data"
      ],
      "metadata": {
        "id": "gEPCV_cfO7rb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "WWG7OWD1ASuM",
        "outputId": "a720832c-932c-42e3-9d9c-bdb696bbd4f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        0     1     2    3     4     5     6     7     8     9   ...     48  \\\n",
              "0     0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
              "1     0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.000   \n",
              "2     0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.010   \n",
              "3     0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.000   \n",
              "4     0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.000   \n",
              "...    ...   ...   ...  ...   ...   ...   ...   ...   ...   ...  ...    ...   \n",
              "4596  0.31  0.00  0.62  0.0  0.00  0.31  0.00  0.00  0.00  0.00  ...  0.000   \n",
              "4597  0.00  0.00  0.00  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
              "4598  0.30  0.00  0.30  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.102   \n",
              "4599  0.96  0.00  0.00  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
              "4600  0.00  0.00  0.65  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
              "\n",
              "         49   50     51     52     53     54   55    56  57  \n",
              "0     0.000  0.0  0.778  0.000  0.000  3.756   61   278   1  \n",
              "1     0.132  0.0  0.372  0.180  0.048  5.114  101  1028   1  \n",
              "2     0.143  0.0  0.276  0.184  0.010  9.821  485  2259   1  \n",
              "3     0.137  0.0  0.137  0.000  0.000  3.537   40   191   1  \n",
              "4     0.135  0.0  0.135  0.000  0.000  3.537   40   191   1  \n",
              "...     ...  ...    ...    ...    ...    ...  ...   ...  ..  \n",
              "4596  0.232  0.0  0.000  0.000  0.000  1.142    3    88   0  \n",
              "4597  0.000  0.0  0.353  0.000  0.000  1.555    4    14   0  \n",
              "4598  0.718  0.0  0.000  0.000  0.000  1.404    6   118   0  \n",
              "4599  0.057  0.0  0.000  0.000  0.000  1.147    5    78   0  \n",
              "4600  0.000  0.0  0.125  0.000  0.000  1.250    5    40   0  \n",
              "\n",
              "[4601 rows x 58 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b59f845f-0c61-431a-80c1-e95a7ca2673f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.778</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.756</td>\n",
              "      <td>61</td>\n",
              "      <td>278</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.21</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.132</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.372</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.048</td>\n",
              "      <td>5.114</td>\n",
              "      <td>101</td>\n",
              "      <td>1028</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.23</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.25</td>\n",
              "      <td>...</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.276</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.010</td>\n",
              "      <td>9.821</td>\n",
              "      <td>485</td>\n",
              "      <td>2259</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4596</th>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.232</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.142</td>\n",
              "      <td>3</td>\n",
              "      <td>88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4597</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.353</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.555</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4598</th>\n",
              "      <td>0.30</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.102</td>\n",
              "      <td>0.718</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.404</td>\n",
              "      <td>6</td>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4599</th>\n",
              "      <td>0.96</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.057</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.147</td>\n",
              "      <td>5</td>\n",
              "      <td>78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4600</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.250</td>\n",
              "      <td>5</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4601 rows Ã— 58 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b59f845f-0c61-431a-80c1-e95a7ca2673f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b59f845f-0c61-431a-80c1-e95a7ca2673f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b59f845f-0c61-431a-80c1-e95a7ca2673f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "raw_url = \"https://raw.githubusercontent.com/n-fleischmann/hw_data/main/spambase.data\"\n",
        "raw_df = pd.read_csv(raw_url, names=list(range(58)))\n",
        "raw_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ys = raw_df[57]\n",
        "xs = raw_df.drop(57, axis=1)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(xs, ys, test_size=0.25, random_state = 2001)"
      ],
      "metadata": {
        "id": "0m5E5XN1BLyF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1"
      ],
      "metadata": {
        "id": "r1oceIQOPBYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logit = LogisticRegression(random_state = 0)\n",
        "logit.fit(x_train, y_train)\n",
        "\n",
        "logit_y_test_pred = logit.predict(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjxofM2TB6qo",
        "outputId": "cf74f870-7bbd-40f0-859a-aca1a5f9d296"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m.confusion_matrix(y_test, logit_y_test_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMr3A_z5CG91",
        "outputId": "0a7a42d4-ddc9-488a-dc0d-b5f7ac4078df"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[659,  43],\n",
              "       [ 39, 410]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(m.classification_report(y_test, logit_y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6r9B43fEZNa",
        "outputId": "645db6ee-5de6-4655-c847-313b24a3bc54"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.94      0.94       702\n",
            "           1       0.91      0.91      0.91       449\n",
            "\n",
            "    accuracy                           0.93      1151\n",
            "   macro avg       0.92      0.93      0.93      1151\n",
            "weighted avg       0.93      0.93      0.93      1151\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m.f1_score(y_test, logit_y_test_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sb7De09YE_Dm",
        "outputId": "06029363-5618-48a0-eac2-dd381fc5a827"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9090909090909092"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logit.coef_.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kK09sOCoP97o",
        "outputId": "b29bb71c-ff7f-4c80-848e-fb9505841c5b"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.170310978564154"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(logit.coef_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1JsYM-aFQUf",
        "outputId": "a0d6a8b3-c69b-4d90-d04f-d3f9e85e5ac3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-7.93453718e-02 -1.94561025e-01  1.66442272e-01  2.28632297e-01\n",
            "   8.49121665e-01  4.89473055e-01  1.17031098e+00  8.49293630e-01\n",
            "   2.50000521e-01  1.48388620e-01  1.83214408e-01  2.69417559e-02\n",
            "   1.25254421e-01  6.80395790e-02  2.74566653e-01  1.08530901e+00\n",
            "   6.42691761e-01  2.93857990e-01  6.94614414e-02  5.66064557e-01\n",
            "   1.95351638e-01  2.49494634e-01  1.09173820e+00  6.40586615e-01\n",
            "  -2.48787496e+00 -1.31671939e+00 -3.53302905e+00 -3.41078611e-01\n",
            "  -6.09691406e-01 -4.04220359e-01 -3.87383024e-01 -2.15991992e-01\n",
            "  -7.00113264e-01 -2.30484611e-01 -5.90537789e-01 -5.18797854e-02\n",
            "  -4.95483958e-01 -1.51590538e-01 -4.61980762e-01 -2.95926936e-01\n",
            "  -3.74413203e-01 -1.01581592e+00 -2.89020263e-01 -5.72503310e-01\n",
            "  -8.70183933e-01 -1.40669903e+00 -9.26623255e-02 -3.11363469e-01\n",
            "  -4.71367768e-01 -2.15318189e-01 -1.30459133e-01  3.30756347e-01\n",
            "   7.62000051e-01  2.29208772e-01  7.06870607e-02  1.09839172e-02\n",
            "   4.56317824e-04]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logit_test_probas = pd.DataFrame(logit.predict_proba(x_test)[:, 1]) #only want prob y=1\n",
        "\n",
        "thresholds = [0.25, 0.5, 0.75, 0.9]\n",
        "\n",
        "for thresh in thresholds:\n",
        "  y_preds = logit_test_probas.applymap(lambda x: 1 if x > thresh else 0 )\n",
        "  print(f\"Threshold: {thresh}  \\t Acc: {m.accuracy_score(y_test, y_preds)} \\t Pres: {m.precision_score(y_test, y_preds)} \\t Rec: {m.recall_score(y_test, y_preds)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SwSWBx8FWmg",
        "outputId": "08c00fd2-3e7c-4d4d-b1b4-189e19da95be"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold: 0.25  \t Acc: 0.8879235447437012 \t Pres: 0.791970802919708 \t Rec: 0.9665924276169265\n",
            "Threshold: 0.5  \t Acc: 0.9287576020851434 \t Pres: 0.9050772626931567 \t Rec: 0.9131403118040089\n",
            "Threshold: 0.75  \t Acc: 0.891398783666377 \t Pres: 0.945054945054945 \t Rec: 0.7661469933184856\n",
            "Threshold: 0.9  \t Acc: 0.8279756733275413 \t Pres: 0.966542750929368 \t Rec: 0.579064587973274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2"
      ],
      "metadata": {
        "id": "cTIe2SMFO5U2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))"
      ],
      "metadata": {
        "id": "oHG6ik0DPN9T"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_theta(theta_old, X, y, lr):\n",
        "  # X : n x d\n",
        "  # theta: d x 1 --> X @ theta: n x 1\n",
        "  # X.T @ y = d x n @ n x 1: d x 1\n",
        "  tmp = sigmoid(X @ theta_old)\n",
        "  grad = (X.T @ (tmp - y))\n",
        "  return theta_old - (lr * grad)"
      ],
      "metadata": {
        "id": "DEhdMuQNO49q"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data_conversion\n",
        "\n",
        "x_train_np = x_train.to_numpy()\n",
        "x_test_np = x_test.to_numpy()\n",
        "\n",
        "y_train_np = y_train.to_numpy()\n",
        "y_test_np = y_test.to_numpy()\n",
        "\n",
        "x_train_np.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-npF0SsSRJek",
        "outputId": "e7245d10-2359-45c4-dc67-dd1d65f84411"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3450, 57)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos_epochs = [10, 50, 100, 1000]\n",
        "alphas = [0.01, 0.1, 0.5, 0.75]\n",
        "\n",
        "results = {}\n",
        "\n",
        "\n",
        "for alpha in alphas:\n",
        "  results[alpha] = {}\n",
        "  for max_epoch in pos_epochs:\n",
        "\n",
        "    results[alpha][max_epoch] = {}\n",
        "    theta = np.ones(x_train_np.shape[1])\n",
        "\n",
        "    for _ in range(max_epoch):\n",
        "      theta = update_theta(theta, x_train_np, y_train_np, alpha)\n",
        "\n",
        "    tmp = pd.DataFrame(sigmoid(x_test_np @ theta))\n",
        "    y_hat = tmp.applymap(lambda x: 1 if x > 0.5 else 0)\n",
        "\n",
        "    results[alpha][max_epoch][\"accuracy\"]   = m.accuracy_score(y_test, y_hat)\n",
        "    results[alpha][max_epoch][\"precision\"]  = m.precision_score(y_test, y_hat)\n",
        "    results[alpha][max_epoch][\"recall\"]     = m.recall_score(y_test, y_hat)\n",
        "    results[alpha][max_epoch][\"f1\"]         = m.f1_score(y_test, y_hat)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "joppG54LGRiL"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for alpha, result in results.items():\n",
        "  print(f\"Alpha: {alpha}\")\n",
        "  for epoch, metrics in result.items():\n",
        "    print(f\"Num Epochs: {epoch}  \\t Acc: {metrics['accuracy']} \\t Pres: {metrics['precision']} \\t Rec: {round(metrics['recall'], 4)} \\t f1: {metrics['f1']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2cyvx_eTHkk",
        "outputId": "9edc1bc3-33f3-4623-98c1-fa988ee4cfb1"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alpha: 0.01\n",
            "Num Epochs: 10  \t Acc: 0.39009556907037357 \t Pres: 0.39009556907037357 \t Rec: 1.0 \t f1: 0.56125\n",
            "Num Epochs: 50  \t Acc: 0.41789748045178104 \t Pres: 0.40125111706881145 \t Rec: 1.0 \t f1: 0.5727040816326531\n",
            "Num Epochs: 100  \t Acc: 0.4152910512597741 \t Pres: 0.4001782531194296 \t Rec: 1.0 \t f1: 0.5716104392106939\n",
            "Num Epochs: 1000  \t Acc: 0.7037358818418766 \t Pres: 0.5981818181818181 \t Rec: 0.7327 \t f1: 0.6586586586586587\n",
            "Alpha: 0.1\n",
            "Num Epochs: 10  \t Acc: 0.39009556907037357 \t Pres: 0.39009556907037357 \t Rec: 1.0 \t f1: 0.56125\n",
            "Num Epochs: 50  \t Acc: 0.39183318853171156 \t Pres: 0.3907745865970409 \t Rec: 1.0 \t f1: 0.5619524405506884\n",
            "Num Epochs: 100  \t Acc: 0.4152910512597741 \t Pres: 0.4001782531194296 \t Rec: 1.0 \t f1: 0.5716104392106939\n",
            "Num Epochs: 1000  \t Acc: 0.6133796698523023 \t Pres: 0.5023866348448688 \t Rec: 0.9376 \t f1: 0.6542346542346542\n",
            "Alpha: 0.5\n",
            "Num Epochs: 10  \t Acc: 0.39009556907037357 \t Pres: 0.39009556907037357 \t Rec: 1.0 \t f1: 0.56125\n",
            "Num Epochs: 50  \t Acc: 0.39183318853171156 \t Pres: 0.3907745865970409 \t Rec: 1.0 \t f1: 0.5619524405506884\n",
            "Num Epochs: 100  \t Acc: 0.4152910512597741 \t Pres: 0.4001782531194296 \t Rec: 1.0 \t f1: 0.5716104392106939\n",
            "Num Epochs: 1000  \t Acc: 0.6333622936576889 \t Pres: 0.5167701863354037 \t Rec: 0.9265 \t f1: 0.6634768740031898\n",
            "Alpha: 0.75\n",
            "Num Epochs: 10  \t Acc: 0.39009556907037357 \t Pres: 0.39009556907037357 \t Rec: 1.0 \t f1: 0.56125\n",
            "Num Epochs: 50  \t Acc: 0.39183318853171156 \t Pres: 0.3907745865970409 \t Rec: 1.0 \t f1: 0.5619524405506884\n",
            "Num Epochs: 100  \t Acc: 0.4152910512597741 \t Pres: 0.4001782531194296 \t Rec: 1.0 \t f1: 0.5716104392106939\n",
            "Num Epochs: 1000  \t Acc: 0.573414422241529 \t Pres: 0.47687224669603523 \t Rec: 0.9644 \t f1: 0.6381724392041268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3"
      ],
      "metadata": {
        "id": "Z8qAF1lNQ_rb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as lda\n",
        "from sklearn.neighbors import KNeighborsClassifier as knn\n",
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "id": "Rr01zhxTVF1v"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_values = [1, 3, 5, 10, 15]\n",
        "kf = KFold(n_splits=len(k_values)) # We want to test 4 values for K in KNN\n",
        "\n",
        "knn_models = {}\n",
        "\n",
        "\n",
        "for i, (train_idx, val_idx) in enumerate(kf.split(x_train)):\n",
        "  x_train_k, x_val = x_train.iloc[train_idx], x_train.iloc[val_idx]\n",
        "  y_train_k, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "  \n",
        "  knn_k = knn(n_neighbors= k_values[i])\n",
        "  knn_k.fit(x_train_k, y_train_k)\n",
        "  y_hat_val = knn_k.predict(x_val)\n",
        "\n",
        "  acc = m.accuracy_score(y_val, y_hat_val)\n",
        "  err = 1 - acc\n",
        "  prec = m.precision_score(y_val, y_hat_val)\n",
        "  rec = m.recall_score(y_val, y_hat_val)\n",
        "\n",
        "  knn_models[i] = {\n",
        "      \"model\": knn_k,\n",
        "      \"acc\": acc,\n",
        "      \"prec\": prec,\n",
        "      \"rec\": rec\n",
        "  }\n",
        "\n",
        "  print(f\"K: {k_values[i]} \\t Acc: {acc} \\t err: {err} \\t prec: {prec} \\t rec: {rec}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSvzQBscRQKA",
        "outputId": "ec66e06a-4042-461a-8417-94cf6278f92e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K: 1 \t Acc: 0.8159420289855073 \t err: 0.18405797101449273 \t prec: 0.7386363636363636 \t rec: 0.7707509881422925\n",
            "K: 3 \t Acc: 0.7942028985507247 \t err: 0.20579710144927532 \t prec: 0.7703703703703704 \t rec: 0.7222222222222222\n",
            "K: 5 \t Acc: 0.8028985507246377 \t err: 0.19710144927536233 \t prec: 0.7977099236641222 \t rec: 0.7157534246575342\n",
            "K: 10 \t Acc: 0.7840579710144927 \t err: 0.2159420289855073 \t prec: 0.762114537444934 \t rec: 0.6455223880597015\n",
            "K: 15 \t Acc: 0.7710144927536232 \t err: 0.22898550724637678 \t prec: 0.7042801556420234 \t rec: 0.688212927756654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn_3 = knn_models[3]['model']\n",
        "lDiscrim = lda()\n",
        "logit_2 = LogisticRegression()\n",
        "\n",
        "lDiscrim.fit(x_train, y_train)\n",
        "logit_2.fit(x_train, y_train)\n",
        "\n",
        "def score_model(model, model_name):\n",
        "  y_hat = model.predict(x_test)\n",
        "\n",
        "  acc = m.accuracy_score(y_test, y_hat)\n",
        "  err = 1 - acc\n",
        "  prec = m.precision_score(y_test, y_hat)\n",
        "  rec = m.recall_score(y_test, y_hat)\n",
        "\n",
        "  template = \"Model: {} \\t Accuracy: {:.4f} \\t Error: {:.4f} \\t Precision: {:.4f} \\t Recall: {:.4f}\" \n",
        "\n",
        "  print(template.format(model_name, acc, err, prec, rec))\n",
        "  \n",
        "score_model(knn_3, \"KNN - 3\")\n",
        "score_model(lDiscrim, \"LDA\")\n",
        "score_model(logit_2, \"Logit\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tagi7ZDxTGow",
        "outputId": "1968470c-1226-4f3c-ac3a-d5b13f0664b1"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: KNN - 3 \t Accuracy: 0.7689 \t Error: 0.2311 \t Precision: 0.7316 \t Recall: 0.6437\n",
            "Model: LDA \t Accuracy: 0.8983 \t Error: 0.1017 \t Precision: 0.9256 \t Recall: 0.8040\n",
            "Model: Logit \t Accuracy: 0.9288 \t Error: 0.0712 \t Precision: 0.9051 \t Recall: 0.9131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import plot_roc_curve #plots the curve using matplotlib and \n",
        "#puts the AUC in the legend\n",
        "\n",
        "plot_roc_curve(logit_2, x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "l-xN0FTff5XH",
        "outputId": "f78d8c29-7a2e-423a-a96f-9d62181846e4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x7ff44d0ef910>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5xVVf3/8debi6KAiIqloIKK3xIQ1EkiQ9QS0VAzScS89UXNr5p3k76aoPZLLTPSKEXl66UELeUrImlaqHQRAR2RixdUREC/EipBiIJ+fn/sPeNhmJmz53LOMHPez8djHrMva+/92efM7LXXWnuvpYjAzMxKV6umDsDMzJqWMwIzsxLnjMDMrMQ5IzAzK3HOCMzMSlybpg6grnbYYYfo3r17U4dhZtaszJkz558R0aW6dc0uI+jevTuzZ89u6jDMzJoVSW/WtM5VQ2ZmJc4ZgZlZiXNGYGZW4pwRmJmVOGcEZmYlrmAZgaQJkt6VNK+G9ZJ0k6RFkuZK2q9QsZiZWc0KWSK4ExhSy/ojgJ7pz5nAbwoYi5mZ1aBg7xFExNOSuteS5Bjg7kj6wX5G0raSdoqItwsVk1lzc+/MJTxUvqypw7DNxN47b8Poo3o1+n6b8oWyrsBbOfNL02WbZASSziQpNbDrrrsWJTgrXZvTxXfmG+8B0L/Hdk0cibVkzeLN4ogYD4wHKCsr80g6JaApL8ab08W3f4/tOKZfV07s7xsgK5ymzAiWAbvkzHdLl1kL0ZCLeVNejH3xtVLTlBnBFOBcSZOA/sAqtw+0HPfOXMJ/T34RqN/F3Bdjs+IpWEYgaSJwMLCDpKXAaKAtQETcAkwDjgQWAWuB7xYqFttYMapdKu7of3JsH1/MzTZzhXxqaESe9QGcU6jjt2QNvZAXo9rFd/RmzUezaCwuZdVd9Bt6IfdF2sxyOSPYTNR0l1/dRd8XcjNrTM4INgO1Naz6om9mheaMYDNQURJww6qZNQVnBE2oojpowdv/on+P7ZwJmFmTcEZQZLltAbn1/8f069qUYZlZCcuUEUhqBfQFdgY+BOZFxLuFDKy5y9L46/p/M9sc1JoRSNoDuAz4OvAqsAJoB+wlaS1wK3BXRHxa6ECbg5ru9nP54m9mm5t8JYIfk4wT8L30BbBKknYETgROBu4qTHibt6p3/b7bN7PmqNaMoLa3g9OqobGNHlEzUtHQu/dO2wC+2zez5qnejcWSDouIxxszmOYi92mfvXfahvu+N6CpQzIzq7eGPDV0B1BSt74VGYCf9jGzliRfY/GUmlYB2zd+OJunmjIAVwGZWUuQr0QwEDgJWFNluYADChLRZij3pS9nAGbW0uTLCJ4B1kbEU1VXSHq5MCFtntwWYGYtVb6nho6oZd1BjR+OmZkVW6umDmBzd+/MJZVtA2ZmLZEzgjwqXhjz00Fm1lK507kauGdQMysVzgiq8LsCZlZqMmcEksZExJia5luCqiOF+VFRMysFdSkRzMkz3+x5pDAzK0WZG4sj4uHa5lsKtweYWanJ18XEzUDUtD4izmv0iMzMrKjyVQ3NLkoUZmbWZPK9WbzRgDOSto6ItYUNyczMiilTG4GkAZIWAC+l830l/bqgkZmZWVFkbSweCxwOrASIiBcA9zVkZtYC1OWpobeqLPqkkWMxM7MmkPU9grckfQUISW2B84GFhQvLzMyKJWuJ4CzgHKArsBzol86bmVkzlykjiIh/RsR3IuJzEdElIk6KiJX5tpM0RNLLkhZJGlXN+l0lTZf0vKS5ko6sz0mYmVn9ZX1qaHdJD0taIeldSQ9J2j3PNq2BccARwN7ACEl7V0l2BXB/ROwLnAD4SSQzsyLLWjV0L3A/sBOwM/B7YGKebQ4AFkXE6xHxMTAJOKZKmgC2Sac7kVQ7mZlZEWXNCLaOiHsiYkP681ugXZ5tugK5TxotTZflGgOcJGkpMA34fnU7knSmpNmSZq9YsSJjyGZmlkWtGYGk7SRtB/xR0ihJ3SXtJukHJBfuhhoB3BkR3YAjgXskbRJTRIyPiLKIKOvSpUsjHNbMzCrke3x0Dkn1jdL57+WsC+CHtWy7DNglZ75buizXSGAIQET8Q1I7YAfg3TxxmZlZI8nX11CPBux7FtBTUg+SDOAE4MQqaZYAXwPulPRFkuom1/2YmRVRXUYo603y9E9l20BE3F1T+ojYIOlc4DGgNTAhIuZLuhqYHRFTgIuB2yRdSFLCOC0iauz22szMGl+mjEDSaOBgkoxgGskjoX8FaswIACJiGlXaEiLiypzpBcCBdYrYzMwaVdanhoaRVOG8ExHfBfqSPO5pZmbNXNaqoQ8j4lNJGyRtQ9KYu0u+jZqLe2cu4aHyZSx4+1/svdM2+TcwM2tBsmYEsyVtC9xG8iTRGuAfBYuqyHIzgWP6VX3VwcysZcuUEUTE2enkLZIeBbaJiLmFC6t47p25hJlvvEf/Httx3/cGNHU4ZmZFl2/w+v1qWxcRzzV+SMX1UHnyaoNLAmZWqvKVCH5ey7oADm3EWJpM/x7bcWL/XZs6DDOzJpHvhbJDihWImZk1jcxDVZqZWcvkjMDMrMQ5IzAzK3FZRyiTpJMkXZnO7yrpgMKGZmZmxZC1RPBrYADJ+AEAq0mGoTQzs2Yu65vF/SNiP0nPA0TE+5K2KGBcZmZWJFlLBOvTwegDQFIX4NOCRWVmZkWTNSO4CZgM7Cjp/5F0Qf2TgkVlZmZFk7Wvod9JmkPSFbWAb0bEwoJGVgS5/QyZmZWqrAPT3ARMiogW1UDsfobMzLJXDc0BrpD0mqQbJJUVMqhicj9DZlbqMmUEEXFXRBwJfAl4Gbhe0qsFjczMzIqirm8W7wl8AdgNeKnxwzEzs2LL+mbxT9MSwNXAPKAsIo4qaGRmZlYUWV8oew0YEBH/LGQwZmZWfPlGKPtCRLwEzAJ2lbRRq2pLGKHMzKzU5SsRXAScSfUjlbWYEcrMzEpZvhHKzkwnj4iIdbnrJLUrWFRmZlY0WZ8a+nvGZWZm1szkayP4PNAV2ErSviTdSwBsA2xd4NjMzKwI8rURHA6cBnQDbsxZvhr47wLFZGZmRZSvjeAu4C5Jx0XEA0WKyczMiihf1dBJEfFboLuki6quj4gbq9nMzMyakXyNxe3T3x2AjtX81ErSEEkvS1okaVQNaY6XtEDSfEn31iF2MzNrBPmqhm5Nf19V1x2nI5qNAw4DlgKzJE2JiAU5aXoCPwQOTIe/3LGux6kvj0VgZpaoS19D20hqK+nPklZIOinPZgcAiyLi9Yj4GJgEHFMlzRnAuIh4HyAi3q3rCdSXxyIwM0tkfY9gcET8CxgKLCbphfTSPNt0Bd7KmV+aLsu1F7CXpL9JekbSkOp2JOlMSbMlzV6xYkXGkPPzWARmZtkzgooqpG8Av4+IVY10/DZAT+BgYARwm6RtqyaKiPERURYRZV26dGmkQ5uZGWTPCKZKegnYH/izpC7AujzbLAN2yZnvli7LtRSYEhHrI+IN4BWSjMHMzIok6whlo4CvkIxDsB74N5vW91c1C+gpqYekLYATgClV0vwvSWkASTuQVBW9njl6MzNrsKyD17cFTgIOkgTwFHBLbdtExAZJ5wKPAa2BCRExX9LVwOyImJKuGyxpAfAJcGlErKz32ZiZWZ1lHZjmN0Bb4Nfp/MnpstNr2ygipgHTqiy7Mmc6SLq63uRlNTMzK46sGcGXIqJvzvxfJL1QiIDMzKy4sjYWfyJpj4oZSbuTVOWYmVkzl7VEcCkwXdLrJF1R7wZ8t2BRmZlZ0eTNCNJHRVeRvClc0QXEyxHxUSEDKyR3L2Fm9plaq4YknQ7MB24GyoHuETG3OWcC4O4lzMxy5SsRXAD0iogVabvA79j0XYBmyd1LmJkl8jUWfxwRKwAi4nVgy8KHZGZmxZSvRNBN0k01zUfEeYUJy8zMiiVfRlC1h9E5hQrEzMyaRpYxi83MrAXL99TQbZJ617CuvaT/lPSdwoRmZmbFkK9qaBxwpaQ+wDxgBdCOpKvobYAJJE8SmZlZM5WvaqgcOF5SB6AM2An4EFgYES8XIT4zMyuwTF1MRMQa4MnChmJmZk0ha6dzZmbWQjkjMDMrcXXKCCRtXahAzMysaWTKCCR9JR1O8qV0vq+kX+fZzMzMmoGsJYJfAIcDKwEi4gXgoEIFZWZmxZO5aigi3qqyyCOUmZm1AFlHKHtL0leAkNQWOB9YWLiwzMysWLKWCM4CzgG6AsuAfsDZhQrKzMyKJ2uJ4D8iYqM+hSQdCPyt8UMyM7NiyloiuDnjMjMza2ZqLRFIGgB8Begi6aKcVdsArQsZmJmZFUe+qqEtgA5puo45y/8FDCtUUGZmVjz5eh99CnhK0p0R8WaRYjIzsyLK2li8VtLPgF4k4xEAEBGHFiQqMzMrmqyNxb8j6V6iB3AVsBiYVaCYzMysiLJmBNtHxB3A+oh4KiL+E3BpwMysBchaNbQ+/f22pG8Ay4HtChOSmZkVU9YSwY8ldQIuBi4BbgcuyLeRpCGSXpa0SNKoWtIdJykklWWMx8zMGknWoSqnppOrgEOg8s3iGklqDYwDDgOWArMkTYmIBVXSdSTpu2hm3UI3M7PGUGuJQFJrSSMkXSKpd7psqKS/A7/Ks+8DgEUR8XpEfAxMAo6pJt01wPXAurqHb2ZmDZWvaugO4HRge+AmSb8FbgB+GhH75tm2K5DbdfXSdFklSfsBu0TEI7XtSNKZkmZLmr1ixYo8hzUzs7rIVzVUBuwTEZ9Kage8A+wRESsbemBJrYAbgdPypY2I8cB4gLKysmjosc3M7DP5SgQfR8SnABGxDni9DpnAMmCXnPlu6bIKHYHewJOSFgNfBqa4wdjMrLjylQi+IGluOi1gj3ReQETEPrVsOwvoKakHSQZwAnBixcqIWAXsUDEv6UngkoiYXeezMDOzesuXEXyxvjuOiA2SzgUeI+mpdEJEzJd0NTA7IqbUd99mZtZ48nU616CO5iJiGjCtyrIra0h7cEOOZWZm9ZN58HozM2uZnBGYmZW4zBmBpK0k/UchgzEzs+LLlBFIOgooBx5N5/tJcmOvmVkLkLVEMIaky4gPACKinGRsAjMza+ayZgTr0+f+c/kNXzOzFiDreATzJZ0ItJbUEzgP+HvhwjIzs2LJWiL4Psl4xR8B95J0R513PAIzM9v8ZS0RfCEiLgcuL2QwZmZWfFlLBD+XtFDSNRXjEpiZWcuQKSOIiENIRiZbAdwq6UVJVxQ0MjMzK4rML5RFxDsRcRNwFsk7BdX2GWRmZs1L1hfKvihpjKQXgZtJnhjqVtDIzMysKLI2Fk8A7gMOj4jlBYzHzMyKLFNGEBEDCh2ImZk1jVozAkn3R8TxaZVQ7pvEWUYoMzOzZiBfieD89PfQQgdiZmZNo9bG4oh4O508OyLezP0Bzi58eGZmVmhZHx89rJplRzRmIGZm1jTytRH8F8md/+6S5uas6gj8rZCBmZlZceRrI7gX+CNwLTAqZ/nqiHivYFGZmVnR5MsIIiIWSzqn6gpJ2zkzMDNr/rKUCIYCc0geH1XOugB2L1BcZmZWJLVmBBExNP3tYSnNzFqorH0NHSipfTp9kqQbJe1a2NDMzKwYsj4++htgraS+wMXAa8A9BYvKzMyKJmtGsCEiAjgG+FVEjCN5hNTMzJq5rL2Prpb0Q+BkYKCkVkDbwoVlZmbFkrVEMJxk4Pr/jIh3SMYi+FnBojIzs6LJOlTlO8DvgE6ShgLrIuLugkZmZmZFkfWpoeOBZ4FvA8cDMyUNy7DdEEkvS1okaVQ16y+StEDSXEl/lrRbXU/AzMwaJmvV0OXAlyLi1Ig4BTgA+FFtG0hqDYwj6Zxub2CEpL2rJHseKEvHNfgD8NO6BF8f985cwsw3/EK0mVmFrBlBq4h4N2d+ZYZtDwAWRcTrEfExMInkqaNKETE9Itams89QhHGQHypfBsAx/boW+lBmZs1C1qeGHpX0GDAxnR8OTMuzTVfgrZz5pUD/WtKPJOngbhOSzgTOBNh114a/x9a/x3ac2N/vw5mZQfYxiy+V9C3gq+mi8RExubGCkHQSUAYMquH444HxAGVlZVFdGjMzq5984xH0BG4A9gBeBC6JiGUZ970M2CVnvlu6rOoxvk7SBjEoIj7KuG8zM2sk+er5JwBTgeNIeiC9uQ77ngX0lNRD0hbACcCU3ASS9gVuBY6u0gZhZmZFkq9qqGNE3JZOvyzpuaw7jogNks4FHgNaAxMiYr6kq4HZETGF5KW0DsDvJQEsiYij63wWZmZWb/kygnbpXXvFOARb5c5HRK0ZQ0RMo0qjckRcmTP99TpHbGZmjSpfRvA2cGPO/Ds58wEcWoigzMysePINTHNIsQIxM7OmkfWFMjMza6GcEZiZlThnBGZmJS5r76NKxyq+Mp3fVdIBhQ3NzMyKIWuJ4NfAAGBEOr+apGfRZsU9j5qZbSprp3P9I2I/Sc8DRMT76dvCzYp7HjUz21TWEsH6dHyBAJDUBfi0YFEVkHseNTPbWNaM4CZgMrCjpP8H/BX4ScGiMjOzosnaDfXvJM0BvkbSvcQ3I2JhQSMzM7OiyJQRSNoVWAs8nLssIpYUKjAzMyuOrI3Fj5C0DwhoB/QAXgZ6FSguMzMrkqxVQ31y5yXtB5xdkIjMzKyo6vVmcdr9dG3jD5uZWTORtY3gopzZVsB+wPKCRGRmZkWVtY2gY870BpI2gwcaPxwzMyu2vBlB+iJZx4i4pAjxmJlZkdXaRiCpTUR8AhxYpHjMzKzI8pUIniVpDyiXNAX4PfDvipUR8WABYzMzsyLI2kbQDlhJMkZxxfsEATgjMDNr5vJlBDumTwzN47MMoEIULCqzjNavX8/SpUtZt25dU4ditllo164d3bp1o23btpm3yZcRtAY6sHEGUMEZgTW5pUuX0rFjR7p3745U3Z+pWemICFauXMnSpUvp0aNH5u3yZQRvR8TVDQvNrHDWrVvnTMAsJYntt9+eFStW1Gm7fG8W+7/LNnvOBMw+U5//h3wZwdfqF4qZmTUXtWYEEeEBfs3y6NChQ4P3MXv2bM4777wa1y9evJh77703c3qA7t2706dPH/bZZx8GDRrEm2++2eA4G8stt9zC3Xff3Sj7evvttxk6dOhGyy644AK6du3Kp59+NpDimDFjuOGGGzZK1717d/75z38C8M4773DCCSewxx57sP/++3PkkUfyyiuvNCi2jz76iOHDh7PnnnvSv39/Fi9eXG26X/7yl/Tu3ZtevXoxduzYyuXDhw+nX79+9OvXj+7du9OvXz8AXnzxRU477bQGxZarXp3OmVnjKisr46abbqpxfdWMIF/6CtOnT2fu3LkcfPDB/PjHP25wnBGx0cW1vs466yxOOeWUBu8H4MYbb+SMM86onP/000+ZPHkyu+yyC0899VSmfUQExx57LAcffDCvvfYac+bM4dprr+X//u//GhTbHXfcQefOnVm0aBEXXnghl1122SZp5s2bx2233cazzz7LCy+8wNSpU1m0aBEA9913H+Xl5ZSXl3PcccfxrW99C4A+ffqwdOlSlixpnCFhsr5HYLbZu+rh+SxY/q9G3efeO2/D6KPqPuxGeXk5Z511FmvXrmWPPfZgwoQJdO7cmVmzZjFy5EhatWrFYYcdxh//+EfmzZvHk08+yQ033MDUqVN56qmnOP/884Gkvvfpp59m1KhRLFy4kH79+nHqqaey7777VqZfs2YN3//+95k9ezaSGD16NMcdd9xG8QwYMKAy41ixYgVnnXVW5UVk7NixHHjggaxYsYITTzyR5cuXM2DAAB5//HHmzJnDmjVrOPzww+nfvz9z5sxh2rRp3H///dx///189NFHHHvssVx11VX8+9//5vjjj2fp0qV88skn/OhHP2L48OGMGjWKKVOm0KZNGwYPHswNN9zAmDFj6NChA5dcckmNn9XBBx9M//79mT59Oh988AF33HEHAwcO3OSzfuCBBzbK5J588kl69erF8OHDmThxIoccckje72v69Om0bduWs846q3JZ37596/y9V/XQQw8xZswYAIYNG8a5555LRGxUj79w4UL69+/P1ltvDcCgQYN48MEH+cEPflCZJiK4//77+ctf/lK57KijjmLSpEkbpasvlwjMCuCUU07h+uuvZ+7cufTp04errroKgO9+97vceuutlJeX07p162q3veGGGxg3bhzl5eXMmDGDrbbaiuuuu46BAwdSXl7OhRdeuFH6a665hk6dOvHiiy8yd+5cDj300E32+eijj/LNb34TgPPPP58LL7yQWbNm8cADD3D66acDcNVVV3HooYcyf/58hg0bttHd5quvvsrZZ5/N/Pnzefnll3n11Vd59tlnKS8vZ86cOTz99NM8+uij7LzzzrzwwgvMmzePIUOGsHLlSiZPnsz8+fOZO3cuV1xxRebPCmDDhg08++yzjB07dqPlFd544w06d+7MlltuWbls4sSJjBgxgmOPPZZHHnmE9evX1/g9VZg3bx77779/3nQAAwcOrKyuyf154oknNkm7bNkydtllFwDatGlDp06dWLly5UZpevfuzYwZM1i5ciVr165l2rRpvPXWWxulmTFjBp/73Ofo2bNn5bKysjJmzJiRKeZ8XCKwFqM+d+6FsGrVKj744AMGDRoEwKmnnsq3v/1tPvjgA1avXs2AAQMAOPHEE5k6deom2x944IFcdNFFfOc73+Fb3/oW3bp1q/V4TzzxBJMmTaqc79y5c+X0IYccwnvvvUeHDh245pprKtMvWLCgMs2//vUv1qxZw1//+lcmT54MwJAhQzbaz2677caXv/xlAP70pz/xpz/9iX333ReANWvW8OqrrzJw4EAuvvhiLrvsMoYOHcrAgQPZsGED7dq1Y+TIkQwdOnSTuvyaPqsKFVUh+++/f7X162+//TZdunSpnP/444+ZNm0aN954Ix07dqR///489thjDB06tManaer6lE1jXXwrfPGLX+Syyy5j8ODBtG/fnn79+m1yk1CRueXacccdWb68cUYDKGiJQNIQSS9LWiRpVDXrt5R0X7p+pqTuhYzHrDkYNWoUt99+Ox9++CEHHnggL730Ur33NX36dN5880369evH6NGjgaQO/Zlnnqmse162bFneBu/27dtXTkcEP/zhDyu3X7RoESNHjmSvvfbiueeeo0+fPlxxxRVcffXVtGnThmeffZZhw4YxdepUhgwZUqf4K+70W7duzYYNGzZZv9VWW230Vvljjz3GBx98QJ8+fejevTt//etfmThxIgDbb78977///kbbr169mm233ZZevXoxZ86cTDHVpUTQtWvXyrv7DRs2sGrVKrbffvtN0o0cObKyZNW5c2f22muvynUbNmzgwQcfZPjw4Rtts27dOrbaaqtMMedTsIwg7b56HHAEsDcwQtLeVZKNBN6PiD2BXwDXFyqee2cuYeYbfgjKCq9Tp0507ty58s7xnnvuYdCgQWy77bZ07NiRmTNnAmx0F5/rtddeo0+fPlx22WV86Utf4qWXXqJjx46sXr262vSHHXYY48aNq5yverFr06YNY8eO5e677+a9995j8ODB3HzzzZXry8vLgaQkcv/99wPJXX/V/VQ4/PDDmTBhAmvWrAGS6o93332X5cuXs/XWW3PSSSdx6aWX8txzz7FmzRpWrVrFkUceyS9+8QteeOGFTJ9VVnvttddGJYWJEydy++23s3jxYhYvXswbb7zB448/ztq1aznooIOYMmVK5ef44IMP0rdvX1q3bs2hhx7KRx99xPjx4yv3NXfu3Grv/mfMmFGZCeb+fP3rX98k7dFHH81dd90FwB/+8AcOPfTQaksg7777LgBLlizhwQcf5MQTT6xc98QTT/CFL3xhk5LhK6+8Qu/evTN/VrUpZNXQAcCiiHgdQNIk4BhgQU6aY4Ax6fQfgF9JUkQ0evcVD5UvSw7Yr2tj79pK3Nq1azf6J73ooou46667KhtAd999d/7nf/4HSJ4iOeOMM2jVqhWDBg2iU6dOm+xv7NixTJ8+nVatWtGrVy+OOOIIWrVqRevWrenbty+nnXZaZbUMwBVXXME555xD7969ad26NaNHj66sUqmw0047MWLECMaNG8dNN93EOeecwz777MOGDRs46KCDuOWWWxg9ejQjRozgnnvuYcCAAXz+85+nY8eOlRf8CoMHD2bhwoWVVVwdOnTgt7/9LYsWLeLSSy+lVatWtG3blt/85jesXr2aY445hnXr1hER3HjjjZucb02fVRbt27dnjz32YNGiRey88848+uij3HLLLRut/+pXv8rDDz/M8OHDOffcc/nqV7+KJHbccUduv/12IKkemjx5MhdccAHXX3897dq1o3v37hs9ylkfI0eO5OSTT2bPPfdku+22q8z8ly9fzumnn860adMAOO6441i5ciVt27Zl3LhxbLvttpX7mDRp0ibVQpCU9r7xjW80KL5KEVGQH2AYcHvO/MnAr6qkmQd0y5l/Ddihmn2dCcwGZu+6665RH2OmzIsxU+bVa1vbfC1YsKCpQ6iT1atXV05fe+21cd555zVhNBtbt25drF+/PiIi/v73v0ffvn2bOKJsHnzwwbj88subOoyiWrduXfTv37/y+6qquv8LYHbUcL1uFo3FETEeGA9QVlZWr9LC5tKQaKXtkUce4dprr2XDhg3stttu3HnnnU0dUqUlS5Zw/PHH8+mnn7LFFltw2223NXVImRx77LGbPInT0i1ZsoTrrruONm0a5xJeyIxgGbBLzny3dFl1aZZKagN0Ihn3wKxFGj58+CaNfpuLnj178vzzzzd1GPVS8QhsqejZs+dGj5I2VCGfGpoF9JTUQ9IWwAnAlCpppgCnptPDgL+kRRizzPwnY/aZ+vw/FCwjiIgNwLnAY8BC4P6ImC/paklHp8nuALaXtAi4CNjkEVOz2rRr146VK1c6MzDjs/EI2rVrV6ft1Nz+gcrKymL27NlNHYZtJjxCmdnGahqhTNKciCirbptm0VhsVpO2bdvWaSQmM9uU+xoyMytxzgjMzEqcMwIzsxLX7BqLJa0A6jvU0g7APxsxnObA51wafM6loSHnvFtEdKluRbPLCBpC0uyaWv2pxk0AAAo/SURBVM1bKp9zafA5l4ZCnbOrhszMSpwzAjOzEldqGcH4/ElaHJ9zafA5l4aCnHNJtRGYmdmmSq1EYGZmVTgjMDMrcS0yI5A0RNLLkhZJ2qRHU0lbSrovXT9TUvfiR9m4MpzzRZIWSJor6c+SdmuKOBtTvnPOSXecpJDU7B81zHLOko5Pv+v5ku4tdoyNLcPf9q6Spkt6Pv37PrIp4mwskiZIelfSvBrWS9JN6ecxV9J+DT5oTUOXNdcfoDXJkJe7A1sALwB7V0lzNnBLOn0CcF9Tx12Ecz4E2Dqd/q9SOOc0XUfgaeAZoKyp4y7C99wTeB7onM7v2NRxF+GcxwP/lU7vDSxu6rgbeM4HAfsB82pYfyTwR0DAl4GZDT1mSywRHAAsiojXI+JjYBJwTJU0xwB3pdN/AL4mSUWMsbHlPeeImB4Ra9PZZ0hGjGvOsnzPANcA1wMtoZ/qLOd8BjAuIt4HiIh3ixxjY8tyzgFsk053ApYXMb5GFxFPA+/VkuQY4O5IPANsK2mnhhyzJWYEXYG3cuaXpsuqTRPJADqrgO2LEl1hZDnnXCNJ7iias7znnBaZd4mIR4oZWAFl+Z73AvaS9DdJz0gaUrToCiPLOY8BTpK0FJgGfL84oTWZuv6/5+XxCEqMpJOAMmBQU8dSSJJaATcCpzVxKMXWhqR66GCSUt/TkvpExAdNGlVhjQDujIifSxoA3COpd0R82tSBNRctsUSwDNglZ75buqzaNJLakBQnVxYlusLIcs5I+jpwOXB0RHxUpNgKJd85dwR6A09KWkxSlzqlmTcYZ/melwJTImJ9RLwBvEKSMTRXWc55JHA/QET8A2hH0jlbS5Xp/70uWmJGMAvoKamHpC1IGoOnVEkzBTg1nR4G/CXSVphmKu85S9oXuJUkE2ju9caQ55wjYlVE7BAR3SOiO0m7yNER0ZzHOc3yt/2/JKUBJO1AUlX0ejGDbGRZznkJ8DUASV8kyQhWFDXK4poCnJI+PfRlYFVEvN2QHba4qqGI2CDpXOAxkicOJkTEfElXA7MjYgpwB0nxcRFJo8wJTRdxw2U8558BHYDfp+3iSyLi6CYLuoEynnOLkvGcHwMGS1oAfAJcGhHNtrSb8ZwvBm6TdCFJw/FpzfnGTtJEksx8h7TdYzTQFiAibiFpBzkSWASsBb7b4GM248/LzMwaQUusGjIzszpwRmBmVuKcEZiZlThnBGZmJc4ZgZlZiXNGUAIkfSKpPOeney1p1zTC8e6U9EZ6rOfStz3ruo/bJe2dTv93lXV/b2iM6X4qPpd5kh6WtG2e9P3q07OlpJ0kTU2nD5a0Kj3uQkmj67G/oyt64ZT0zYrPKZ2/On1xsEHS73BYnjRP1uUFvfTcp2ZIV23vm5JukHRo1uNZds4ISsOHEdEv52dxEY55aUT0A0aRvMhWJxFxekQsSGf/u8q6rzRCfPDZ59Kb5H2Sc/Kk70fy/HZdXQTcljM/I/1sykj6yKlTN8IRMSUirktnv0nS42bFuisj4ol6xLg5uROoro+km0n+nqyROSMoQZI6KBmT4DlJL0rapNfO9C726Zw75oHp8sGS/pFu+3tJHfIc7mlgz3Tbi9J9zZN0QbqsvaRHJL2QLh+eLn9SUpmk64Ct0jh+l65bk/6eJOkbOTHfKWmYpNaSfiZplpL+2r+X4WP5B2nHXZIOSM/xeUl/l/Qf6VutVwPD01iGp7FPkPRsmra63k8BjgMerbowIv4NzAH2TEsbz6TxTpbUOY3lPH02jsSkdNlpkn4l6SvA0cDP0pj2yPkMhkj6fc5nU3k3XtfvUNKV6Wc5T9J4aaOeek/O+Rs5IE2f9XOpVk29b0bEm8D2kj5fl/1ZBk3R37Z/ivtD8oZpefozmeSN8m3SdTuQvKFY8XLhmvT3xcDl6XRrkr57diC5sLdPl18GXFnN8e4EhqXT3wZmAvsDLwLtSd5wng/sS3KRvC1n207p7ydJxw+oiCknTUWMxwJ3pdNbkPTIuBVwJnBFunxLYDbQo5o41+Sc3++BIen8NkCbdPrrwAPp9GnAr3K2/wlwUjq9LUm/Pu2rHKMHMCdn/mBgajq9PbAY6AXMBQaly68GxqbTy4EtK45RNY7czzp3Pv2Ol+R8V78BTqrnd7hdzvJ7gKNyvqPb0umDSPvPr+lzqXLuZcDttfzNdqea/vhJSlbHNfX/VEv7aXFdTFi1PoykKgIASW2Bn0g6CPiU5E74c8A7OdvMAiakaf83IsolDSKphvhbelO4BcmddHV+JukKkj5fRpL0BTM5krtgJD0IDCS5U/65pOtJLhIz6nBefwR+KWlLkqqEpyPiQ0mDgX1y6rg7kXS89kaV7beSVJ6e/0Lg8Zz0d0nqSdJlQdsajj8YOFrSJel8O2DXdF8VdmLTfm8GSnqe5LO/jqSjuG0j4ql0/V0kGRMkGcTvJP0vST9CmUTSNcOjwFGS/gB8A/gBSa+zWb/DCodI+gGwNbAdSSb+cLpuYnq8pyVto6SdpabPJTe+2cDpWc8nx7vAzvXYzmrhjKA0fQfoAuwfEeuV9M7ZLjdB+o99EMkF5E5JNwLvA49HxIgMx7g0Iv5QMSPpa9UliohX0jryI4EfS/pzRFyd5SQiYp2kJ4HDgeEkg5ZAMnLT9yPisTy7+DAi+knamqQvm3OAm0gGs5keEccqaVh/sobtRXJ3+nJtx6DKZ0vSRjC0cidSp1q2/wbJ3fZRwOWS+tSStqpJwLkk1SyzI2J1Wq2T9TtEUjvg1ySls7ckjWHj86naR01Qw+ci6XN1iL0m7Ug+U2tEbiMoTZ2Ad9NM4BBgk/GLlYxp/H8RcRtwO8nQec8AB0qqqPNvL2mvjMecAXxT0taS2pNU68yQtDOwNiJ+S9IxXnUNp+vTkkl17iPpdKuidAHJRf2/KraRtFd6zGpFMnLbecDF+qxb8opufU/LSbqapIqswmPA9yvqzJX08FrVKyTVHDWKiFXA+0rbYYCTgaeUjKmwS0RMJ6nC6URSrZaraky5niL5PM/gs0yyrt9hxUX/n2lbQtUniSradL5K0gvmKrJ9LvW1F1DtWL5Wf84IStPvgDJJLwKnAC9Vk+Zg4IW0CmM48MuIWEFyYZwoaS5JlcIXshwwIp4jqXd+lqTN4PaIeB7oAzybVtGMBn5czebjgblKG4ur+BNJdccTkQxlCEnGtQB4TskjiLeSp/SbxjKXZJCTnwLXpueeu910YO+KxmKSkkPbNLb56XzV/f4beK3iwluLU0mq0+aSPJ10NUnbxW/T7+l54KbYdICZScClaaPsHlWO/QkwFTgi/U1dv8P0eLeRXHwfI6kyzLUu/ZxuIakChAyfi5IHAW6v7phKet/8B/AfkpZKGpkub0vy4EFz7kp8s+TeR80KTNKxJNVwVzR1LM1Z+jnuFxE/aupYWhq3EZgVWERMltScx8TeXLQBft7UQbRELhGYmZU4txGYmZU4ZwRmZiXOGYGZWYlzRmBmVuKcEZiZlbj/D4Bc0ntgaUvNAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Doing it manually\n",
        "thresholds = [x / 10 for x in range(0, 11)]\n",
        "\n",
        "\"\"\"\n",
        "y_pred\t\ty_true\t\ty_pred-y_true\t\ttype\n",
        "0\t\t\t\t0\t\t\t0\t\t\t\tTrue Negative\n",
        "0\t\t\t\t1\t\t\t-1\t\t\tFalse Negative\n",
        "1\t\t\t\t0\t\t\t1\t\t\t\tFalse Positive\n",
        "1\t\t\t\t1\t\t\t0\t\t\t\tTrue Positive\n",
        "\n",
        "True positive rate = recall\n",
        "False positive rate = [count of 1 in y_pred-y_true] / [count of 0 in y_true]\n",
        "\"\"\"\n",
        "\n",
        "TPRs, FPRs = [], []\n",
        "y_probas = pd.DataFrame(logit_2.predict_proba(x_test)[:, 0])\n",
        "\n",
        "for threshold in thresholds:\n",
        "  y_pred = y_probas.applymap(lambda x : 1.0 if x >= threshold else 0.0)\n",
        "  \n",
        "  false_pos = 0\n",
        "  y_ts = 0\n",
        "  for p, t in zip(y_pred[0].to_list(), y_test.to_list()):\n",
        "    if t == 0: y_ts += 1\n",
        "    if p == 1 and t == 0: false_pos += 1\n",
        "\n",
        "  FPRs.append(false_pos / y_ts)\n",
        "  TPRs.append(m.recall_score(y_test, y_pred))\n",
        "  \n"
      ],
      "metadata": {
        "id": "Y046XLd3gWz4"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "PjLnZSAmlYls"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(TPRs, FPRs)\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate or Recall\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "LZm2vclJt70H",
        "outputId": "72355453-0306-4bc8-e723-93596039a017"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'True Positive Rate or Recall')"
            ]
          },
          "metadata": {},
          "execution_count": 106
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 4"
      ],
      "metadata": {
        "id": "dRGWoMpdN2_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def k_fold_CV(k):\n",
        "\n",
        "  import warnings\n",
        "  warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "  fold_size = len(x_train_np) // k\n",
        "  leftovers = len(x_train_np) % k\n",
        "\n",
        "  lda_errors = []\n",
        "  logit_errors = []\n",
        "\n",
        "  for i in range(k):\n",
        "    x_start = x_train_np[: fold_size * i]\n",
        "    x_end = x_train_np[fold_size * (i + 1):]\n",
        "\n",
        "    y_start = y_train_np[: fold_size * i]\n",
        "    y_end = y_train_np[fold_size * (i + 1):]\n",
        "\n",
        "    x_train_k = np.concatenate((x_start, x_end))\n",
        "    y_train_k = np.concatenate((y_start, y_end))\n",
        "\n",
        "    x_val = x_train_np[fold_size * i: fold_size * (i + 1)]\n",
        "    y_val = y_train_np[fold_size * i: fold_size * (i + 1)]\n",
        "\n",
        "    ldis_k = lda()\n",
        "    logit_k = LogisticRegression()\n",
        "\n",
        "    ldis_k.fit(x_train_k, y_train_k)\n",
        "    logit_k.fit(x_train_k, y_train_k)\n",
        "\n",
        "    lda_error = 1 - m.accuracy_score(y_val, ldis_k.predict(x_val))\n",
        "    logit_error = 1 - m.accuracy_score(y_val, logit_k.predict(x_val))\n",
        "\n",
        "    lda_errors.append(lda_error) \n",
        "    logit_errors.append(logit_error)\n",
        "\n",
        "    print(f\"Fold: {i + 1}/{k} \\t LDA Error: {round(lda_error, 4)} \\t Logit Error: {round(logit_error, 4)}\")\n",
        "\n",
        "  print(f\"\\n Average Validation Error \\nLDA: {round(sum(lda_errors) / len(lda_errors), 4)}\\nLogit: {round(sum(logit_errors) / len(logit_errors), 4)}\")"
      ],
      "metadata": {
        "id": "An-P9vH9t-2Q"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_fold_CV(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QlgOZvVHcKO",
        "outputId": "9fe7e4d0-90a0-4e2f-b606-aab18a8f4253"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold: 1/5 \t LDA Error: 0.1101 \t Logit Error: 0.0797\n",
            "Fold: 2/5 \t LDA Error: 0.0942 \t Logit Error: 0.0638\n",
            "Fold: 3/5 \t LDA Error: 0.113 \t Logit Error: 0.0855\n",
            "Fold: 4/5 \t LDA Error: 0.1275 \t Logit Error: 0.0855\n",
            "Fold: 5/5 \t LDA Error: 0.1333 \t Logit Error: 0.0957\n",
            "\n",
            " Average Validation Error \n",
            "LDA: 0.1157\n",
            "Logit: 0.082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k_fold_CV(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CogbTEghHegP",
        "outputId": "1f8a6427-f0f2-4f9c-d551-8132bbe2ca0f"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold: 1/10 \t LDA Error: 0.1246 \t Logit Error: 0.1043\n",
            "Fold: 2/10 \t LDA Error: 0.0986 \t Logit Error: 0.0522\n",
            "Fold: 3/10 \t LDA Error: 0.1101 \t Logit Error: 0.0696\n",
            "Fold: 4/10 \t LDA Error: 0.0899 \t Logit Error: 0.058\n",
            "Fold: 5/10 \t LDA Error: 0.1362 \t Logit Error: 0.1043\n",
            "Fold: 6/10 \t LDA Error: 0.0841 \t Logit Error: 0.0696\n",
            "Fold: 7/10 \t LDA Error: 0.1275 \t Logit Error: 0.0899\n",
            "Fold: 8/10 \t LDA Error: 0.1246 \t Logit Error: 0.0841\n",
            "Fold: 9/10 \t LDA Error: 0.1478 \t Logit Error: 0.1043\n",
            "Fold: 10/10 \t LDA Error: 0.1159 \t Logit Error: 0.1014\n",
            "\n",
            " Average Validation Error \n",
            "LDA: 0.1159\n",
            "Logit: 0.0838\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "F3soOtuqMsX1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}